{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入第三方包\n",
    "from rosbags.rosbag2 import Reader\n",
    "from rosbags.serde import deserialize_cdr\n",
    "import os, copy,traceback\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 屏蔽warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# 数据合规性检查\n",
    "from OmniScape_nav_lint import *\n",
    "lint = OmniScapeNavLint()\n",
    "\n",
    "from msgRegister import *\n",
    "\n",
    "from coord_convert.transform import wgs2gcj, wgs2bd, gcj2wgs, gcj2bd, bd2wgs, bd2gcj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 功能\n",
    "\n",
    "\n",
    "\n",
    "### 使用说明\n",
    "\n",
    "输入输出路径尽量放在固态盘下，实测固态盘和机械盘有16倍速度差距\n",
    "\n",
    "OmniScape_nav_DB3解码工具（OmniScape_nav_DB3_parse.ipynb）为【HIT导航所智能感知信息处理团队-导航组】一站式数据源解析工具，适配导航车\n",
    "\n",
    "Appendix 代码块为数据查询和说明功能，可注释不影响运行。\n",
    "\n",
    "### 版本说明\n",
    "| 版本       | 描述                                   |  时间 | 处理人 |\n",
    "| --------- | -------------------------------------- |  -------- |-------- |\n",
    "| v0.1      | 数据包读入，图片/文件导出，时间轴检查，话题名检查 |  2025-03-07 |李昕达 |\n",
    "\n",
    "### 参数配置\n",
    "\n",
    "#### topicFileMap 配置说明\n",
    "| key       | 描述                                   |\n",
    "| --------- | -------------------------------------- |\n",
    "| type      | 类型，主要为IMU，GNSS，Base(真值)，Image，CompressedImage，Other类型 |\n",
    "| topic     | 话题名，查询话题名运行代码块appendix.1 |\n",
    "| filename  | 导出为csv的文件名                      |\n",
    "| foldTopic | rosbag包话题有嵌套，这个列表负责展开这些嵌套，一般不需要动  |\n",
    "| imgDir    | 仅Image，CompressedImage类型有效，图片路径，建议放固态盘  |\n",
    "\n",
    "\n",
    "IMU，GNSS，Base(真值)的数量分别只能有一个，Image，CompressedImage导出图片，Other直出CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rosbag文件路径\n",
    "DB3Filename = r'E:\\NAV_DATASETS\\CrossLoc\\kc_htg'\n",
    "topicFilePrefix = DB3Filename+\"/toCSV/\" # 转csv的目录 默认\"./toCSV/\"\n",
    "imgFilePrefix = DB3Filename+\"/toImg/\" # 转图片的目录 默认\"./toImg/\"\n",
    "\n",
    "lint.DB3Check(DB3Filename)\n",
    "lint.dirExistCheck([topicFilePrefix,imgFilePrefix])\n",
    "\n",
    "# 要转的topic\n",
    "topicFileMap = [\n",
    "    {\"type\":\"IMU\",              \"topic\":\"/XSENSE6\",                       \"fileName\":\"XSENSE_IMU.csv\",          \"foldTopic\":[]},\n",
    "    {\"type\":\"GNSS\",             \"topic\":\"/GNSS_0\",                        \"fileName\":\"GNSS_0.csv\",               \"foldTopic\":[\"datahpposllh\",\"datasat\",\"datarawx\"]},\n",
    "    {\"type\":\"Base\",             \"topic\":\"/CGI10103\",                      \"fileName\":\"CGI10103.csv\",            \"foldTopic\":[]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/livox/lidar\",                   \"fileName\":\"livox_lidar.csv\",         \"foldTopic\":[]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/livox/imu\",                     \"fileName\":\"livox_imu.csv\",           \"foldTopic\":[]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/UWB3\",                          \"fileName\":\"UWB3.csv\",                \"foldTopic\":[\"data\"]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/UWB4\",                          \"fileName\":\"UWB4.csv\",                \"foldTopic\":[\"data\"]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/UWB7\",                          \"fileName\":\"UWB7.csv\",                \"foldTopic\":[\"data\"]},\n",
    "    {\"type\":\"Other\",            \"topic\":\"/d435i/middle/imu\",                     \"fileName\":\"d435i_imu.csv\",           \"foldTopic\":[]},\n",
    "    {\"type\":\"CompressedImage\",  \"topic\":\"/flir_camera/image_raw/compressed\",    \"imgDir\":\"flir_camera/\"},\n",
    "    {\"type\":\"CompressedImage\",  \"topic\":\"/hk_camera/rgb/compressed\",            \"imgDir\":\"hk_camera/\"},\n",
    "    {\"type\":\"CompressedImage\", \"topic\":\"/d435i/middle/color/image_raw/compressed\", \"imgDir\":\"d435i/color/\"}, \n",
    "    # {\"type\":\"CompressedImage\", \"topic\":\"/d435i/middle/infra1/image_rect_raw/compressed\", \"imgDir\":\"d435i/infra1/\"},\n",
    "    # {\"type\":\"CompressedImage\", \"topic\":\"/d435i/middle/infra2/image_rect_raw/compressed\", \"imgDir\":\"d435i/infra2/\"},\n",
    "        # yi\n",
    "    \n",
    "    # {\"type\":\"Other\",            \"topic\":\"/node2/uwb_nooploop_uwb_info_\",        \"fileName\":\"node2_info.csv\",           \"foldTopic\":[\"data\"]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/node1/uwb_nooploop_uwb_info_\",        \"fileName\":\"node1_info.csv\",           \"foldTopic\":[\"data\"]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/node1/mti_info_radxaMTi7Node\",         \"fileName\":\"node1_mti_info.csv\",           \"foldTopic\":[]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/node2/mti_info_radxaMTi7Node\",         \"fileName\":\"node2_mti_info.csv\",           \"foldTopic\":[]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/node1/mti_status_radxaMTi7Node\",        \"fileName\":\"node1_status.csv\",           \"foldTopic\":[]},\n",
    "    # {\"type\":\"Other\",            \"topic\":\"/node2/mti_status_radxaMTi7Node\",        \"fileName\":\"node2_status.csv\",           \"foldTopic\":[]},\n",
    "]\n",
    "\n",
    "\n",
    "# 根据topic自动配置msg\n",
    "topic2msgDict = {}\n",
    "with Reader(DB3Filename) as reader:\n",
    "    for connection in reader.connections: topic2msgDict[connection.topic] = connection.msgtype\n",
    "    \n",
    "lint.topicMsgCheck(topicFileMap, topic2msgDict)\n",
    "for topic in topicFileMap:\n",
    "    if topic[\"topic\"] in topic2msgDict: topic[\"msgType\"] = topic2msgDict[topic[\"topic\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时间轴检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicList = [x[\"topic\"] for x in topicFileMap]\n",
    "timeLine = {}\n",
    "for topic in topicList:  timeLine[topic] = []\n",
    "with Reader(DB3Filename) as reader:\n",
    "    obj_connections = [x for x in reader.connections if x.topic in topicList]\n",
    "    for connection, timestamp,_ in tqdm(reader.messages(connections=obj_connections), desc=\"时间轴解析中\"):\n",
    "        timeLine[connection.topic].append(timestamp)\n",
    "lint = OmniScapeNavLint()\n",
    "lint.timeLineCheck(topicList, timeLine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卫星数量检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnssSysList2dict(gnssSysList):\n",
    "    return {\n",
    "        \"GPS\":gnssSysList.count(\"GPS\"),\n",
    "        \"GAL\":gnssSysList.count(\"GAL\"),\n",
    "        \"BDS\":gnssSysList.count(\"BDS\"),\n",
    "        \"GLO\":gnssSysList.count(\"GLO\"),\n",
    "        \"ALL\":len(gnssSysList)\n",
    "            }\n",
    "gnssid2SatSysDict = {0:\"GPS\",2:\"GAL\",3:\"BDS\",5:\"?\",6:\"GLO\"}\n",
    "datarawxList = []\n",
    "with Reader(DB3Filename) as reader: \n",
    "    obj_connections = [x for x in reader.connections if x.topic == \"/GNSS_0\"]\n",
    "    for connection, timestamp, rawdata in tqdm(reader.messages(connections=obj_connections), desc=\"GNSS数据解析\"):\n",
    "        msg = deserialize_cdr(rawdata, connection.msgtype, typestore)\n",
    "        datarawxList.append(msg.datarawx)\n",
    "        \n",
    "gnssidList = []\n",
    "for datarawxItem in datarawxList:\n",
    "    gnssidList.append(gnssSysList2dict([gnssid2SatSysDict[rawxBlock.gnssid] for rawxBlock in datarawxItem]))\n",
    "    \n",
    "df_gnssidList = pd.DataFrame(gnssidList)\n",
    "df_gnssidList.plot(figsize=(12,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出为图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgtopicList = []\n",
    "compressedtopicList = []\n",
    "for topicDict in topicFileMap:\n",
    "    if topicDict[\"type\"] == \"CompressedImage\":        compressedtopicList.append(topicDict[\"topic\"])\n",
    "    elif topicDict[\"type\"] == \"Image\":                imgtopicList.append(topicDict[\"topic\"])\n",
    "print(len(compressedtopicList))\n",
    "if len(compressedtopicList) > 0:\n",
    "    with Reader(DB3Filename) as reader:\n",
    "        # CompressedImage\n",
    "        obj_connections = [x for x in reader.connections if x.topic in compressedtopicList]\n",
    "        for connection, timestamp, rawdata in tqdm(reader.messages(connections=obj_connections), desc=\"图片导出\"):\n",
    "            msg = deserialize_cdr(rawdata, connection.msgtype, typestore)\n",
    "            [img,timestamp] = [msg.data,msg.header.stamp.sec+msg.header.stamp.nanosec/1e9]# 获取图片和时间戳\n",
    "            imgName = msg.header.frame_id+\" \"+str(round(timestamp,6))# 获取图片名称\n",
    "            # print(imgName)\n",
    "            imgDir = \"\"\n",
    "            for topicInfo in topicFileMap:\n",
    "                if topicInfo[\"topic\"] == connection.topic:\n",
    "                    imgDir = topicInfo[\"imgDir\"]\n",
    "                    break\n",
    "            os.makedirs(os.path.join(imgFilePrefix, imgDir), exist_ok=True)\n",
    "            imgPath = os.path.join(imgFilePrefix, imgDir, imgName+\".png\")\n",
    "            if not os.path.exists(imgPath):\n",
    "                with open(imgPath, \"wb\") as f:   f.write(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出为CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topicDict in topicFileMap:\n",
    "    msgList = []\n",
    "    if \"fileName\" not in topicDict: continue\n",
    "    try:\n",
    "        with Reader(DB3Filename) as reader:\n",
    "            obj_connections = [x for x in reader.connections if x.topic == topicDict[\"topic\"]]\n",
    "            for connection, timestamp, rawdata in tqdm(reader.messages(connections=obj_connections), desc=\"CSV导出\"+topicDict[\"topic\"]):\n",
    "                msg = deserialize_cdr(rawdata, connection.msgtype, typestore)\n",
    "                dictMsg = copy.deepcopy(msg.__dict__)\n",
    "                dictMsg['stamp_sec'] = msg.header.stamp.sec\n",
    "                dictMsg['stamp_nanosec'] = msg.header.stamp.nanosec\n",
    "                dictMsg['header'] = \"\"\n",
    "                if len(topicDict[\"foldTopic\"]) > 0:\n",
    "                    for foldTopic in topicDict[\"foldTopic\"]:\n",
    "                        if foldTopic in dictMsg:\n",
    "                            if len(dictMsg[foldTopic]) < 1: continue\n",
    "                            keys = dictMsg[foldTopic][0].__dict__.keys()\n",
    "                            for key in keys:\n",
    "                                dictMsg[foldTopic+\"_\"+key] = [x.__getattribute__(key) for x in dictMsg[foldTopic]]\n",
    "                                if len(dictMsg[foldTopic+\"_\"+key]) == 1:\n",
    "                                    dictMsg[foldTopic+\"_\"+key] = dictMsg[foldTopic+\"_\"+key][0]\n",
    "                        del dictMsg[foldTopic]\n",
    "                msgList.append(dictMsg)\n",
    "        csvFileName = os.path.join(topicFilePrefix, topicDict[\"fileName\"])\n",
    "        df = pd.DataFrame(msgList)\n",
    "        df.to_csv(csvFileName, index=False)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc();\n",
    "        lint.logger.info(f\"CSV导出失败  {topicDict['topic']}：\"+str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 画出真值和GNSS的运动轨迹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posTopicFileMap = [\n",
    "    {\"type\":\"GNSS\",             \"topic\":\"/GNSS_0\",                        \"fileName\":\"GNSS_0.csv\",               \"foldTopic\":[\"datahpposllh\",\"datasat\",\"datarawx\"]},\n",
    "    {\"type\":\"Base\",             \"topic\":\"/CGI10103\",                      \"fileName\":\"CGI10103.csv\",            \"foldTopic\":[]},\n",
    "]\n",
    "llhGNSS = {\"lat\":[],\"lon\":[],\"alt\":[]}\n",
    "llhBase = {\"lat\":[],\"lon\":[],\"alt\":[],\"status_L\":[], \"status_H\":[],\"status_desc\":[]}\n",
    "\n",
    "s = 0.5\n",
    "# matplotlib 中文\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def bytes2hexstr(bytes):\n",
    "    return ''.join(['%02X ' % b for b in bytes])\n",
    "\n",
    "# GNSS\n",
    "with Reader(DB3Filename) as reader: \n",
    "    obj_connections = [x for x in reader.connections if x.topic == posTopicFileMap[0][\"topic\"]]\n",
    "    for connection, timestamp, rawdata in tqdm(reader.messages(connections=obj_connections), desc=\"GNSS数据解析\"):\n",
    "        # print(bytes2hexstr(rawdata[:]))\n",
    "        msg = deserialize_cdr(rawdata, connection.msgtype, typestore)\n",
    "        lat = (msg.datahpposllh[0].lat+msg.datahpposllh[0].lathp*1e-2)*1e-7\n",
    "        lon = (msg.datahpposllh[0].lon+msg.datahpposllh[0].lonhp*1e-2)*1e-7\n",
    "        alt = (msg.datahpposllh[0].height+msg.datahpposllh[0].heighthp*1e-2)*1e-7\n",
    "        if lat > 40 and lat < 45.76 and lon >120 and lon <130:\n",
    "            llhGNSS[\"lat\"].append((msg.datahpposllh[0].lat+msg.datahpposllh[0].lathp*1e-2)*1e-7)\n",
    "            llhGNSS[\"lon\"].append((msg.datahpposllh[0].lon+msg.datahpposllh[0].lonhp*1e-2)*1e-7)\n",
    "            llhGNSS[\"alt\"].append((msg.datahpposllh[0].height+msg.datahpposllh[0].heighthp*1e-2)*1e-7)\n",
    "\n",
    "def statusDescMap(H):\n",
    "    LowDict = {        \"0\":\"定位中\",        \"1\":\"粗对准\",        \"2\":\"精对准\",        \"3\":\"GNSS定位\",        \"4\":\"GNSS定向\" ,\n",
    "                \"5\":\"RTK定位\",        \"6\":\"DMI组合\",        \"7\":\"DMI标定\",        \"8\":\"纯惯性\",        \"9\":\"零速校正\",\n",
    "                \"A\":\"VG模式\",        \"B\":\"RTK定向\",        \"C\":\"初始化\"}\n",
    "    HighDict  = {        \"0\":\"GNSS单点定位\",        \"2\":\"SBAS模式\",        \"4\":\"RTK固定解\",        \"5\":\"RTK浮点解\"    }\n",
    "    return HighDict[H]\n",
    "\n",
    "# Base\n",
    "with Reader(DB3Filename) as reader: \n",
    "    obj_connections = [x for x in reader.connections if x.topic == posTopicFileMap[1][\"topic\"]]\n",
    "    for connection, timestamp, rawdata in tqdm(reader.messages(connections=obj_connections), desc=\"真值数据解析\"):\n",
    "        msg = deserialize_cdr(rawdata, connection.msgtype, typestore)\n",
    "        if len(msg.fpd_gnsssta) > 1:\n",
    "            llhBase[\"lat\"].append(msg.fpd_gnsslatitude)\n",
    "            llhBase[\"lon\"].append(msg.fpd_gnsslongitude)\n",
    "            llhBase[\"alt\"].append(msg.fpd_gnssaltitude)\n",
    "            llhBase[\"status_L\"].append(str(msg.fpd_gnsssta)[-1])\n",
    "            llhBase[\"status_H\"].append(str(msg.fpd_gnsssta)[0])\n",
    "            llhBase[\"status_desc\"].append(statusDescMap(llhBase[\"status_H\"][-1]))\n",
    "\n",
    "'''\n",
    "Low :0：定位中1：粗对准2：精对准3：GNSS定位4：GNSS定向5：RTK定位6：DMI组合7：DMI标定8：纯惯性9：零速校正A:VG模式B:RTK定向C：初始化\n",
    "High :O:GNSS单点定位2：SBAS模式4：RTK固定解5：RTK浮点解\n",
    "'''\n",
    "\n",
    "# 定义状态对应的颜色映射\n",
    "status_colors = {\n",
    "    \"GNSS单点定位\": \"red\",\n",
    "    \"RTK固定解\": \"green\",\n",
    "    \"RTK浮点解\": \"orange\",\n",
    "    # 可以根据需要添加其他状态的颜色\n",
    "}\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(llhGNSS[\"lon\"], llhGNSS[\"lat\"], label=\"GNSS\",s=s)\n",
    "\n",
    "df = pd.DataFrame(llhBase)\n",
    "# 根据状态分段绘制轨迹\n",
    "\n",
    "\n",
    "for status in status_colors:\n",
    "    mask = df['status_desc'] == status  # 假设状态描述存储在 'status_desc' 列中\n",
    "    plt.scatter(df.loc[mask, \"lon\"], \n",
    "            df.loc[mask, \"lat\"], \n",
    "            color=status_colors[status],\n",
    "            label=f\"Base ({status})\",s=s)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用folium绘制轨迹\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import branca.colormap as cm\n",
    "\n",
    "llhBaseMod100 = {key: llhBase[key][::100] for key in llhBase}  # 每100个点取一个，减少数据量\n",
    "\n",
    "# 创建地图\n",
    "m = folium.Map(\n",
    "            # tiles='https://webrd02.is.autonavi.com/appmaptile?lang=en&size=1&scale=1&style=8&x={x}&y={y}&z={z}',# 道路底图\n",
    "            tiles='http://wprd02.is.autonavi.com/appmaptile?lang=zh_cn&size=1&style=6&x={x}&y={y}&z={z}', # 卫星底图\n",
    "            attr='高德-中英文对照',\n",
    "            control_scale=True,\n",
    "            max_zoom=18,\n",
    "            min_zoom=5,\n",
    "            overlay=True,\n",
    "            prefer_canvas=True,\n",
    "            opacity=0.7,\n",
    "            zoom_start=16)\n",
    "\n",
    "# 定义状态对应的颜色映射\n",
    "status_colors = {\n",
    "    \"GNSS单点定位\": \"red\",\n",
    "    \"RTK固定解\": \"green\",\n",
    "    \"RTK浮点解\": \"orange\",\n",
    "    # 可以根据需要添加其他状态的颜色\n",
    "}\n",
    "\n",
    "# 将llhGNSS数据添加到地图 - 使用散点图\n",
    "for i in range(len(llhGNSS[\"lat\"])):\n",
    "    lon,lat = wgs2gcj(llhGNSS[\"lon\"][i], llhGNSS[\"lat\"][i])\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=1,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='blue',\n",
    "        fill_opacity=0.1,  # 降低透明度，使点更透明\n",
    "        popup=\"GNSS点\"\n",
    "    ).add_to(m)\n",
    "\n",
    "# 将llhBase数据按状态分组添加到地图\n",
    "df = pd.DataFrame(llhBaseMod100)\n",
    "\n",
    "# 根据状态分段绘制散点图\n",
    "for status in status_colors:\n",
    "    mask = df['status_desc'] == status\n",
    "    if mask.any():  # 确保有匹配的数据\n",
    "        status_df = df.loc[mask]\n",
    "        print(len(status_df))\n",
    "        for _, row in status_df.iterrows():\n",
    "            lon,lat = wgs2gcj(row[\"lon\"], row[\"lat\"])\n",
    "            folium.CircleMarker(\n",
    "                location=[lat, lon],\n",
    "                radius=1,\n",
    "                color=status_colors[status],\n",
    "                fill=True,\n",
    "                fill_color=status_colors[status],\n",
    "                fill_opacity=0.1,\n",
    "                popup=f\"Base点 ({status})\"\n",
    "            ).add_to(m)\n",
    "\n",
    "# 添加图例\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed;      bottom: 50px; right: 50px;  border:2px solid grey; z-index:9999; \n",
    "            background-color:white; padding: 10px;font-size:14px; \">\n",
    "    <p><b>图例</b></p> <p><i class=\"fa fa-circle\" style=\"color:blue\"></i> GNSS</p>\n",
    "'''\n",
    "\n",
    "for status, color in status_colors.items():\n",
    "    legend_html += f'<p><i class=\"fa fa-circle\" style=\"color:{color}\"></i> Base ({status})</p>'\n",
    "\n",
    "legend_html += '</div>'\n",
    "\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# 根据llhBase的范围调整地图视图\n",
    "if not df.empty:\n",
    "    # 计算llhBase数据的边界\n",
    "    min_lat = df['lat'].min()\n",
    "    max_lat = df['lat'].max()\n",
    "    min_lon = df['lon'].min()\n",
    "    max_lon = df['lon'].max()\n",
    "    \n",
    "    # 计算中心点\n",
    "    center_lat = (min_lat + max_lat) / 2\n",
    "    center_lon = (min_lon + max_lon) / 2\n",
    "    \n",
    "    # 设置地图中心点\n",
    "    m.location = [center_lat, center_lon]\n",
    "    \n",
    "    # 计算适当的缩放级别\n",
    "    # 添加一些边距\n",
    "    lat_padding = (max_lat - min_lat) * 0.1\n",
    "    lon_padding = (max_lon - min_lon) * 0.1\n",
    "    \n",
    "    # 调整地图边界\n",
    "    m.fit_bounds([\n",
    "        [min_lat - lat_padding, min_lon - lon_padding],\n",
    "        [max_lat + lat_padding, max_lon + lon_padding]\n",
    "    ])\n",
    "    \n",
    "    print(f\"地图已调整到llhBase数据范围: 纬度({min_lat:.6f}~{max_lat:.6f}), 经度({min_lon:.6f}~{max_lon:.6f})\")\n",
    "else:\n",
    "    print(\"警告: llhBase数据为空，无法调整地图视图\")\n",
    "\n",
    "\n",
    "# 设置初始缩放级别\n",
    "m.zoom_start = 18\n",
    "\n",
    "\n",
    "# 显示地图\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4),dpi=200)\n",
    "plt.plot(df['lat'].diff().tolist()[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出为*.ros_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rosPickle = {\"IMU\":[],\"GNSS\":[],\"Base\":[]}\n",
    "rosPickleTopicDict = [x for x in topicFileMap if x[\"type\"] in [\"IMU\",\"Base\"]]\n",
    "for topicDict in rosPickleTopicDict:\n",
    "    msgList = []\n",
    "    try:\n",
    "        with Reader(DB3Filename) as reader:\n",
    "            obj_connections = [x for x in reader.connections if x.topic == topicDict[\"topic\"]]\n",
    "            for connection, timestamp, rawdata in tqdm(reader.messages(connections=obj_connections), desc=\"ros pickle导出\"+topicDict[\"topic\"]):\n",
    "                msg = deserialize_cdr(rawdata, connection.msgtype, typestore)\n",
    "                dictMsg = copy.deepcopy(msg.__dict__)\n",
    "                dictMsg['stamp_sec'] = msg.header.stamp.sec\n",
    "                dictMsg['stamp_nanosec'] = msg.header.stamp.nanosec\n",
    "                dictMsg['header'] = \"\"\n",
    "                if len(topicDict[\"foldTopic\"]) > 0:\n",
    "                    for foldTopic in topicDict[\"foldTopic\"]:\n",
    "                        if foldTopic in dictMsg:\n",
    "                            if len(dictMsg[foldTopic]) < 1: continue\n",
    "                            keys = dictMsg[foldTopic][0].__dict__.keys()\n",
    "                            for key in keys:\n",
    "                                dictMsg[foldTopic+\"_\"+key] = [x.__getattribute__(key) for x in dictMsg[foldTopic]]\n",
    "                                if len(dictMsg[foldTopic+\"_\"+key]) == 1:\n",
    "                                    dictMsg[foldTopic+\"_\"+key] = dictMsg[foldTopic+\"_\"+key][0]\n",
    "                        del dictMsg[foldTopic]\n",
    "                msgList.append(dictMsg)\n",
    "        for topicType in [\"IMU\",\"Base\"]:\n",
    "            if topicDict[\"type\"] == topicType:\n",
    "                rosPickle[topicType] = copy.deepcopy(msgList)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        lint.logger.info(f\"ros pickle 导出失败  {topicDict['topic']}：\"+str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单独适配GNSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rosPickleTopicDict = [x for x in topicFileMap if x[\"type\"] in [\"GNSS\"]]\n",
    "breakFlag = False\n",
    "for topicDict in rosPickleTopicDict:\n",
    "    msgList = []\n",
    "    with Reader(DB3Filename) as reader:\n",
    "        obj_connections = [x for x in reader.connections if x.topic == topicDict[\"topic\"]]\n",
    "        for connection, timestamp, rawdata in tqdm(reader.messages(connections=obj_connections), desc=\"ros pickle导出\"+topicDict[\"topic\"]):\n",
    "            msg = deserialize_cdr(rawdata, connection.msgtype, typestore)\n",
    "            dictMsg = copy.deepcopy(msg.__dict__)\n",
    "            dictMsg['stamp_sec'] = msg.header.stamp.sec\n",
    "            dictMsg['stamp_nanosec'] = msg.header.stamp.nanosec\n",
    "            dictMsg['header'] = \"\"\n",
    "            if len(topicDict[\"foldTopic\"]) > 0:\n",
    "                for foldTopic in topicDict[\"foldTopic\"]:\n",
    "                    if len(dictMsg[foldTopic]) < 1: continue\n",
    "                    keys = dictMsg[foldTopic][0].__dict__.keys()\n",
    "                    # print(foldTopic,keys)\n",
    "                    # print(foldTopic,foldTopic == 'datasat')\n",
    "                    # print(dictMsg.keys())\n",
    "                    if foldTopic == 'datasat':\n",
    "                        for key in keys:\n",
    "                            # dictMsg[foldTopic+\"_\"+key] = [x.__getattribute__(key) for x in dictMsg[foldTopic]]\n",
    "                            rawxSatMap = {}\n",
    "                            # print(foldTopic,keys)\n",
    "                            # print(dictMsg[foldTopic][0].__getattribute__(list(keys)[0]))\n",
    "                            for epoch in dictMsg[foldTopic]:\n",
    "                                satGnssId,satSvid = epoch.__getattribute__('gnssid'),epoch.__getattribute__('svid')\n",
    "                                satElev,satAzim,satCn0 = epoch.__getattribute__('elev'),epoch.__getattribute__('azim'),epoch.__getattribute__('cno')\n",
    "                                rawxSatMap[\"{:03d}-{:03d}\".format(satGnssId,satSvid)] = {\"elev\":satElev,\"azim\":satAzim,\"cn0\":satCn0}\n",
    "                                # print(\"{:03d}-{:03d}\".format(satGnssId,satSvid), satGnssId, satSvid, satElev, satAzim, satCn0)\n",
    "                            # if foldtopic == \"datasat\":\n",
    "                            #     satGnssIdList,satSvidList,satElevList,satAzimList,satCn0List = \n",
    "                    else:\n",
    "                        for key in keys:\n",
    "                            # print(foldTopic+\"_\"+key)\n",
    "                            dictMsg[foldTopic+\"_\"+key] = [x.__getattribute__(key) for x in dictMsg[foldTopic]]\n",
    "                            if len(dictMsg[foldTopic+\"_\"+key]) == 1:\n",
    "                                dictMsg[foldTopic+\"_\"+key] = dictMsg[foldTopic+\"_\"+key][0]\n",
    "                    del dictMsg[foldTopic]\n",
    "                    breakFlag = True\n",
    "                    # break\n",
    "            try:\n",
    "                rawxGnssIdList,rawxSvidList = dictMsg[\"datarawx_gnssid\"],dictMsg[\"datarawx_svid\"]\n",
    "                matchedElevList,matchedAzimList,matchedCn0List = [],[],[]\n",
    "                for indexSat in range(len(dictMsg[\"datarawx_gnssid\"])):\n",
    "                    rawexGnssId,rawxSvid = dictMsg[\"datarawx_gnssid\"][indexSat],dictMsg[\"datarawx_svid\"][indexSat]\n",
    "                    # print(\"{:03d}-{:03d}\".format(rawexGnssId,rawxSvid))\n",
    "                    # print(rawxSatMap[\"{:03d}-{:03d}\".format(rawexGnssId,rawxSvid)])\n",
    "                    matchedDict = rawxSatMap[\"{:03d}-{:03d}\".format(rawexGnssId,rawxSvid)]\n",
    "                    matchedElevList.append(matchedDict[\"elev\"])\n",
    "                    matchedAzimList.append(matchedDict[\"azim\"])\n",
    "                    matchedCn0List.append(matchedDict[\"cn0\"])\n",
    "                dictMsg[\"datasat_elev\"] = matchedElevList\n",
    "                dictMsg[\"datasat_azim\"] = matchedAzimList\n",
    "                dictMsg[\"datasat_cno\"] = matchedCn0List\n",
    "                dictMsg[\"datasat_numsvs\"] = len(matchedElevList)\n",
    "            except:\n",
    "                dictMsg[\"datasat_elev\"],dictMsg[\"datasat_azim\"],dictMsg[\"datasat_cno\"] = [],[],[]\n",
    "                dictMsg[\"datarawx_gnssid\"],dictMsg[\"datarawx_svid\"] = [],[]\n",
    "                dictMsg[\"datasat_numsvs\"] = 0\n",
    "            \n",
    "            msgList.append(dictMsg)\n",
    "for topicType in [\"GNSS\"]:\n",
    "    if topicDict[\"type\"] == topicType:\n",
    "        rosPickle[topicType] = copy.deepcopy(msgList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toImgPath = []\n",
    "for topicFile in topicFileMap:\n",
    "    if topicFile['type'] == \"CompressedImage\":\n",
    "        toImgPath.append(topicFile)\n",
    "    \n",
    "rosPickle[\"toImgPath\"] = toImgPath    \n",
    "rosPickle[\"rosbagFilePath\"] = DB3Filename\n",
    "with open(\"name.ros_pickle\",\"wb\") as f:\n",
    "    pickle.dump(rosPickle,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix.1\n",
    "话题名查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "with Reader(DB3Filename) as reader:\n",
    "    # topic and msgtype information is available on .connections list\n",
    "    for connection in reader.connections:\n",
    "        count += 1\n",
    "        print(str(count)+\"话题名：\"+connection.topic+\" \"*(60-len(connection.topic)), str(count)+\"msg名：\"+connection.msgtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navDataParse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
